+ SINGLE=0
+ ARNOLD_WORKER_NUM=1
+ ARNOLD_ID=0
+ BATCH_SIZE=32
++ wc -l
++ nvidia-smi --query-gpu=index --format=csv,noheader
+ NUM_GPUS=2
+ exp_name=version1_trangnvt2_bs32_gpu2
+ nproc_per_node=
+ '[' '!' -z 0 ']'
+ '[' 0 '!=' 0 ']'
+ MASTER_NODE_ID=0
+ nnodes=1
+ node_rank=0
+ master_addr=METIS_WORKER_0_HOST
+ master_addr=
+ master_port=METIS_WORKER_0_PORT
+ master_port=
+ ports=(`echo $master_port | tr ',' ' '`)
++ echo
++ tr , ' '
+ master_port=
+ master_addr=127.0.0.1
+ master_port=12348
+ nproc_per_node=2
+ echo '[nproc_per_node: 2]'
+ echo '[nnodes: 1]'
+ echo '[node_rank: 0]'
+ echo '[master_addr: 127.0.0.1]'
+ echo '[master_port: 12348]'
+ export OMP_NUM_THREADS=8
+ OMP_NUM_THREADS=8
+ export NCCL_IB_DISABLE=0
+ NCCL_IB_DISABLE=0
+ export NCCL_IB_GID_INDEX=3
+ NCCL_IB_GID_INDEX=3
+ BED=checkpoints
+ LOCAL_OUT=local_output
+ mkdir -p checkpoints
+ mkdir -p local_output
+ export COMPILE_GAN=0
+ COMPILE_GAN=0
+ export USE_TIMELINE_SDK=1
+ USE_TIMELINE_SDK=1
+ export CUDA_TIMER_STREAM_KAFKA_CLUSTER=bmq_data_va
+ CUDA_TIMER_STREAM_KAFKA_CLUSTER=bmq_data_va
+ export CUDA_TIMER_STREAM_KAFKA_TOPIC=megatron_cuda_timer_tracing_original_v2
+ CUDA_TIMER_STREAM_KAFKA_TOPIC=megatron_cuda_timer_tracing_original_v2
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ wandb offline
+ bed_path=checkpoints/version1_trangnvt2_bs32_gpu2/
+ data_path=../RepControlNet/data/canny_laion/infinity_10k/splits
+ video_data_path=
+ local_out_path=local_output/version1_trangnvt2_bs32_gpu2
+ torchrun --nproc_per_node=2 --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --master_port=12348 train.py --ep=100 --opt=adamw --cum=3 --sche=lin0 --fp16=2 --ada=0.9_0.97 --tini=-1 --tclip=5 --flash=0 --alng=5e-06 --saln=1 --cos=1 --enable_checkpointing=full-block --local_out_path local_output/version1_trangnvt2_bs32_gpu2 --task_type=t2i --bed=checkpoints/version1_trangnvt2_bs32_gpu2/ --data_path=../RepControlNet/data/canny_laion/infinity_10k/splits --video_data_path= --exp_name=version1_trangnvt2_bs32_gpu2 --tblr=1.2e-4 --pn 0.06M --model=2bc8 --lbs 32 --workers=8 --short_cap_prob 0.5 --online_t5=1 --use_streaming_dataset 1 --iterable_data_buffersize 30000 --Ct5=2048 --t5_path=google/flan-t5-xl --vae_type 32 --vae_ckpt=weights/infinity_vae_d32_rdn_short.pth --wp 0.00000001 --wpe=1 --dynamic_resolution_across_gpus 1 --enable_dynamic_length_prompt 1 --reweight_loss_by_scale 1 --add_lvl_embeding_only_first_block 1 --rope2d_each_sa_layer 1 --rope2d_normalized_by_hw 2 --use_fsdp_model_ema 0 --always_training_scales 100 --use_bit_label 1 --zero=2 --save_model_iters_freq 100 --log_freq=50 --checkpoint_type=torch --prefetch_factor=16 --noise_apply_strength 0.3 --noise_apply_layers 13 --apply_spatial_patchify 0 --use_flex_attn=True --pad=128 --use_image_adapter=1 --condition_folder=../RepControlNet/data/canny_laion/infinity_10k/condition_canny --image_folder=../RepControlNet/data/canny_laion/infinity_10k/images --pretrained_path weights/infinity_2b_reg.pth --tlr 1.8e-4
[W315 14:44:52.139801186 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W315 14:44:52.981704809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[rank1]:[W315 14:44:52.999590922 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank0]:[W315 14:44:52.999606011 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
slurmstepd: error: *** JOB 146530 ON sdc2-hpc-dgx-a100-012 CANCELLED AT 2025-03-15T14:44:56 ***
