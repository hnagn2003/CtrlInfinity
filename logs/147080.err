+ init_port=12345
+ true
+ nc -z 127.0.0.1 12345
+ break
+ SINGLE=0
+ ARNOLD_WORKER_NUM=1
+ ARNOLD_ID=0
+ COND_PATH=../RepControlNet/data/canny_laion/infinity_10k/condition_canny
+ IMAGE_PATH=../RepControlNet/data/canny_laion/infinity_10k/images
+ data_path=../RepControlNet/data/canny_laion/infinity_10k/splits
+ BATCH_SIZE=32
+ base_pretrained_path=weights/infinity_2b_reg.pth
+ adapter_pretrained_path=abc
+ eval_vae_path=weights/vae32reg.pth
+ eval_vae_config=weights/vae32reg.json
+ LEARNING_RATE=0.00075
+ val_log_freq=100
++ nvidia-smi --query-gpu=index --format=csv,noheader
++ wc -l
+ NUM_GPUS=1
+ NUM_GPUS=1
+ '[' -z '' ']'
+ DESIGN_VERSION=0
+ exp_name=version_0_ngannh9_bs32_gpu1_lr_0.00075
+ '[' '!' -z 0 ']'
+ '[' 0 '!=' 0 ']'
+ MASTER_NODE_ID=0
+ nnodes=1
+ node_rank=0
+ master_addr=METIS_WORKER_0_HOST
+ master_addr=
+ master_port=METIS_WORKER_0_PORT
+ master_port=
+ ports=(`echo $master_port | tr ',' ' '`)
++ echo
++ tr , ' '
+ master_port=
+ master_addr=127.0.0.1
+ master_port=12345
+ nproc_per_node=1
+ echo '[nproc_per_node: 1]'
+ echo '[nnodes: 1]'
+ echo '[node_rank: 0]'
+ echo '[master_addr: 127.0.0.1]'
+ echo '[master_port: 12345]'
+ export OMP_NUM_THREADS=8
+ OMP_NUM_THREADS=8
+ export NCCL_IB_DISABLE=0
+ NCCL_IB_DISABLE=0
+ export NCCL_IB_GID_INDEX=3
+ NCCL_IB_GID_INDEX=3
+ BED=checkpoints_2_reproduce
+ LOCAL_OUT=local_output_2_reproduce
+ mkdir -p checkpoints_2_reproduce
+ mkdir -p local_output_2_reproduce
+ export COMPILE_GAN=0
+ COMPILE_GAN=0
+ export USE_TIMELINE_SDK=1
+ USE_TIMELINE_SDK=1
+ export CUDA_TIMER_STREAM_KAFKA_CLUSTER=bmq_data_va
+ CUDA_TIMER_STREAM_KAFKA_CLUSTER=bmq_data_va
+ export CUDA_TIMER_STREAM_KAFKA_TOPIC=megatron_cuda_timer_tracing_original_v2
+ CUDA_TIMER_STREAM_KAFKA_TOPIC=megatron_cuda_timer_tracing_original_v2
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ wandb disabled
+ bed_path=checkpoints_2_reproduce/version_0_ngannh9_bs32_gpu1_lr_0.00075/
+ video_data_path=
+ local_out_path=local_output_2_reproduce/version_0_ngannh9_bs32_gpu1_lr_0.00075
+ DESIGN_VERSION=0
+ torchrun --nproc_per_node=1 --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --master_port=12345 train.py --ep=100 --opt=adamw --cum=3 --sche=lin0 --fp16=2 --ada=0.9_0.97 --tini=-1 --tclip=5 --flash=0 --alng=5e-06 --saln=1 --cos=1 --enable_checkpointing=full-block --local_out_path local_output_2_reproduce/version_0_ngannh9_bs32_gpu1_lr_0.00075 --task_type=t2i --bed=checkpoints_2_reproduce/version_0_ngannh9_bs32_gpu1_lr_0.00075/ --data_path=../RepControlNet/data/canny_laion/infinity_10k/splits --video_data_path= --exp_name=version_0_ngannh9_bs32_gpu1_lr_0.00075 --pn 0.06M --model=2bc8 --lbs 32 --workers=2 --short_cap_prob 0.5 --online_t5=1 --use_streaming_dataset 1 --iterable_data_buffersize 30000 --Ct5=2048 --t5_path=google/flan-t5-xl --vae_type 32 --vae_ckpt=weights/infinity_vae_d32_reg.pth --wp 0.00000001 --wpe=1 --dynamic_resolution_across_gpus 1 --enable_dynamic_length_prompt 1 --reweight_loss_by_scale 1 --add_lvl_embeding_only_first_block 1 --rope2d_each_sa_layer 1 --rope2d_normalized_by_hw 2 --use_fsdp_model_ema 0 --always_training_scales 100 --use_bit_label 1 --zero=2 --save_model_iters_freq 300 --log_freq=100 --checkpoint_type=torch --prefetch_factor=16 --noise_apply_strength 0.3 --noise_apply_layers 13 --apply_spatial_patchify 0 --use_flex_attn=True --pad=128 --use_image_adapter=1 --condition_folder=../RepControlNet/data/canny_laion/infinity_10k/condition_canny --image_folder=../RepControlNet/data/canny_laion/infinity_10k/images --pretrained_path weights/infinity_2b_reg.pth --adapter_pretrained_path abc --tblr=0.00075 --validation False --eval_vae_path weights/vae32reg.pth --eval_vae_config weights/vae32reg.json --auto_resume False --rush_resume weights/infinity_2b_reg.pth --fused_norm False --seed 710
[W321 03:18:52.829046651 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[rank0]:[W321 03:18:53.420700920 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py:91: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  vae_ckpt = torch.load(args.vae_ckpt, map_location='cpu')
/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/torch/nn/init.py:51: UserWarning: Specified kernel cache directory is not writable! This disables kernel caching. Specified directory is /lustre/scratch/client/movian/research/users/ngannh9/Infinity/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1460.)
  tensor.erfinv_()
/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py:175: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  cpu_d = torch.load(args.rush_resume, 'cpu')
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards:  50%|#####     | 1/2 [00:00<00:00,  1.28it/s]
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=> Traceback (most recent call last):
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 699, in <module>
    main()
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 682, in main
    main_train(args)
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 367, in main_train
    ret = build_everything_from_args(args, saver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 94, in build_everything_from_args
    text_tokenizer, text_encoder, vae_local, gpt_uncompiled, gpt_wo_ddp, gpt_ddp, gpt_wo_ddp_ema, gpt_ddp_ema, gpt_optim = build_model_optimizer(args, vae_ckpt)
                                                                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 319, in build_model_optimizer
    text_encoder: T5EncoderModel = T5EncoderModel.from_pretrained(args.t5_path, torch_dtype=torch.float16)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/transformers/modeling_utils.py", line 262, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4022, in from_pretrained
    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/transformers/utils/hub.py", line 1037, in get_checkpoint_shard_files
    cached_filename = cached_file(
                      ^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/transformers/utils/hub.py", line 342, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 862, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1010, in _hf_hub_download_to_cache_dir
    with WeakFileLock(lock_path):
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/huggingface_hub/utils/_fixes.py", line 109, in WeakFileLock
    lock.acquire(timeout=min(log_interval, timeout - elapsed_time) if timeout else log_interval)
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/filelock/_api.py", line 332, in acquire
    self._acquire()
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=>   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/filelock/_unix.py", line 42, in _acquire
    fd = os.open(self.lock_file, open_flags, self._context.mode)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[03-21 04:19:17] (/python3.11/traceback.py, line1022)=> PermissionError: [Errno 13] Permission denied: '/lustre/scratch/client/movian/research/users/ngannh9/Infinity/.cache/huggingface/hub/.locks/models--google--flan-t5-xl/c0c677ddeb21009b6efd97146f37fc3a0396707fb5e63ade7aff64884dce9806.lock'
[rank0]: Traceback (most recent call last):
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 711, in <module>
[rank0]:     raise _e
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 699, in <module>
[rank0]:     main()
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 682, in main
[rank0]:     main_train(args)
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 367, in main_train
[rank0]:     ret = build_everything_from_args(args, saver)
[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 94, in build_everything_from_args
[rank0]:     text_tokenizer, text_encoder, vae_local, gpt_uncompiled, gpt_wo_ddp, gpt_ddp, gpt_wo_ddp_ema, gpt_ddp_ema, gpt_optim = build_model_optimizer(args, vae_ckpt)
[rank0]:                                                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/train.py", line 319, in build_model_optimizer
[rank0]:     text_encoder: T5EncoderModel = T5EncoderModel.from_pretrained(args.t5_path, torch_dtype=torch.float16)
[rank0]:                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/transformers/modeling_utils.py", line 262, in _wrapper
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4022, in from_pretrained
[rank0]:     resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(
[rank0]:                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/transformers/utils/hub.py", line 1037, in get_checkpoint_shard_files
[rank0]:     cached_filename = cached_file(
[rank0]:                       ^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/transformers/utils/hub.py", line 342, in cached_file
[rank0]:     resolved_file = hf_hub_download(
[rank0]:                     ^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 862, in hf_hub_download
[rank0]:     return _hf_hub_download_to_cache_dir(
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1010, in _hf_hub_download_to_cache_dir
[rank0]:     with WeakFileLock(lock_path):
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/contextlib.py", line 137, in __enter__
[rank0]:     return next(self.gen)
[rank0]:            ^^^^^^^^^^^^^^
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/huggingface_hub/utils/_fixes.py", line 109, in WeakFileLock
[rank0]:     lock.acquire(timeout=min(log_interval, timeout - elapsed_time) if timeout else log_interval)
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/filelock/_api.py", line 332, in acquire
[rank0]:     self._acquire()
[rank0]:   File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/filelock/_unix.py", line 42, in _acquire
[rank0]:     fd = os.open(self.lock_file, open_flags, self._context.mode)
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: PermissionError: [Errno 13] Permission denied: '/lustre/scratch/client/movian/research/users/ngannh9/Infinity/.cache/huggingface/hub/.locks/models--google--flan-t5-xl/c0c677ddeb21009b6efd97146f37fc3a0396707fb5e63ade7aff64884dce9806.lock'
E0321 03:19:20.096000 4091008 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 4091315) of binary: /lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/bin/python
Traceback (most recent call last):
  File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/scratch/client/movian/research/users/ngannh9/Infinity/env/flashattn/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-03-21_03:19:20
  host      : sdc2-hpc-dgx-a100-012
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4091315)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
